{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19d4c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display,Markdown\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871aaaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d0ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a69c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "google_client = OpenAI(api_key=GOOGLE_API_KEY, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai\")\n",
    "groq_client = OpenAI(api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f32fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = [{\n",
    "    \"name\": \"gemini-2.0-flash\",\n",
    "    \"client\": google_client,\n",
    "},\n",
    "{\n",
    "    \"name\": \"gpt-4o-mini\",\n",
    "    \"client\": openai_client,\n",
    "},\n",
    "{\n",
    "    \"name\": \"llama-3.3-70b-versatile\",\n",
    "    \"client\": groq_client,\n",
    "},\n",
    "{\n",
    "    \"name\": \"o3-mini\",\n",
    "    \"client\": openai_client,\n",
    "}\n",
    "]\n",
    "answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c10f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_prompt = \"Generate a complex research question on explainable AI for different AI models to answer. Just generate the question, no other text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": question_prompt\n",
    "}]\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2849c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do the intrinsic design, learning mechanisms, and data representations across diverse AI models impact the formulation, effectiveness, and evaluation of explainable AI techniques, and what standardized methodologies can be developed to ensure consistent interpretability and actionable insights across these heterogeneous systems?\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.chat.completions.create(model=\"o3-mini\", messages=message)\n",
    "\n",
    "debate_question = response.choices[0].message.content\n",
    "\n",
    "print(debate_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99c028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'you are a debate expert. You are given a question and you need to answer it. Make sure to answer to the best of your ability. The question is: How do the intrinsic design, learning mechanisms, and data representations across diverse AI models impact the formulation, effectiveness, and evaluation of explainable AI techniques, and what standardized methodologies can be developed to ensure consistent interpretability and actionable insights across these heterogeneous systems?'}]\n"
     ]
    }
   ],
   "source": [
    "#Now, we iterate through the competitors and get the answers\n",
    "\n",
    "debate_question = f\"you are a debate expert. You are given a question and you need to answer it. Make sure to answer to the best of your ability. The question is: {debate_question}\"\n",
    "\n",
    "debate_message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": debate_question\n",
    "}]\n",
    "\n",
    "print(debate_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43884703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting answer from gemini-2.0-flash\n",
      "Getting answer from gpt-4o-mini\n",
      "Getting answer from llama-3.3-70b-versatile\n",
      "Getting answer from o3-mini\n"
     ]
    }
   ],
   "source": [
    "for competitor in competitors:\n",
    "    print(f\"Getting answer from {competitor['name']}\")\n",
    "    response = competitor[\"client\"].chat.completions.create(model=competitor[\"name\"], messages=debate_message)\n",
    "    answers.append(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through answers and print them\n",
    "for answer in answers:\n",
    "    print(display(Markdown(answer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "128e0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors_response = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    competitors_response += f\"Answer {index + 1}:\\n{answer}\\n\\n\"\n",
    "\n",
    "judge_prompt = f\"\"\"\n",
    "You are a debate judge. You are given a question and you need to judge the answers from the competitors. The question is: {debate_question}\n",
    "You are given the following answers:\n",
    "{competitors_response}\n",
    "\n",
    "You need to rank the answers based on what you consider the best based on the question and the following criteria:\n",
    "- The answer should be the most relevant to the question\n",
    "- The answer should be the most accurate to the question\n",
    "- The answer should be the most comprehensive to the question\n",
    "- The answer should be the most persuasive to the question\n",
    "- The answer should be the most logical to the question\n",
    "- The answer should be the most consistent to the question\n",
    "\n",
    "The rank should be from 1 to 4. Where 1 is the best and 4 is the worst.\n",
    "\n",
    "provide the answer in json format with the following structure:\n",
    "{{\n",
    "    \"rank\": [\n",
    "        {{\n",
    "            \"index\": \"index of the answer\",\n",
    "            \"score\": \"score of the answer\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Do not include any other text in your response. And don't respond with markdown.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e38337",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": judge_prompt\n",
    "}]\n",
    "\n",
    "judge_response = openai_client.chat.completions.create(model=\"o3-mini\", messages=judge_message)\n",
    "\n",
    "print(judge_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e36409",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = json.loads(judge_response.choices[0].message.content)\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba682bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: o3-mini\n",
      "Rank 3: llama-3.3-70b-versatile\n",
      "Rank 4: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "for index, rank in enumerate(results_dict[\"rank\"]):\n",
    "    print(f\"Rank {index + 1}: {competitors[int(rank['index'])-1]['name']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
